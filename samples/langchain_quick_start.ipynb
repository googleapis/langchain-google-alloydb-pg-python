{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upi2EY4L9ei3"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbF2F2miAT4a"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googleapis/langchain-google-alloydb-pg-python/blob/main/samples/langchain_quick_start.ipynb)\n",
    "\n",
    "---\n",
    "# Introduction\n",
    "\n",
    "In this codelab, you'll learn how to create a powerful interactive generative AI application using Retrieval Augmented Generation powered by [AlloyDB for PostgreSQL](https://cloud.google.com/alloydb) and [LangChain](https://www.langchain.com/). We will be creating an application grounded in a [Netflix Movie dataset](https://www.kaggle.com/datasets/shivamb/netflix-shows), allowing you to interact with movie data in exciting new ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ma6pEng3ypbA"
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "* A basic understanding of the Google Cloud Console\n",
    "* Basic skills in command line interface and Google Cloud shell\n",
    "* Basic python knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzDgqJHgysy1"
   },
   "source": [
    "## What you'll learn\n",
    "\n",
    "* How to deploy a AlloyDB for PostgreSQL instance\n",
    "* How to use AlloyDB for PostgreSQL as a VectorStore\n",
    "* How to use AlloyDB for PostgreSQL as a DocumentLoader\n",
    "* How to use AlloyDB for PostgreSQL for ChatHistory storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbcZUjT1yvTq"
   },
   "source": [
    "## What you'll need\n",
    "\n",
    "* A Google Cloud Account and Google Cloud Project\n",
    "* A web browser such as [Chrome](https://www.google.com/chrome/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHdR4fF3vLWA"
   },
   "source": [
    "# Setup and Requirements\n",
    "\n",
    "In the following instructions you will learn to:\n",
    "\n",
    "1. Install required dependencies for our application\n",
    "2. Set up authentication for our project\n",
    "3. Set up a AlloyDB for PostgreSQL Instance\n",
    "4. Import the data used by our application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uy9KqgPQ4GBi"
   },
   "source": [
    "## Install dependencies\n",
    "First you will need to install the dependencies needed to run this demo app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_ppDxYf4Gqs"
   },
   "outputs": [],
   "source": [
    "%pip install langchain-google-alloydb-pg langchain langchain-google-vertexai google-cloud-alloydb-connector[pg8000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DeUbHclxw7_l"
   },
   "source": [
    "## Authenticate to Google Cloud within Colab\n",
    "In order to access your Google Cloud Project from this notebook, you will need to Authenticate as an IAM user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Q9hyqdyEx6l"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCiNGP1Qxd6x"
   },
   "source": [
    "## Connect Your Google Cloud Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SLUGlG6UE2CK"
   },
   "outputs": [],
   "source": [
    "# @markdown Please fill in the value below with your GCP project ID and then run the cell.\n",
    "\n",
    "# Please fill in these values.\n",
    "project_id = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# Quick input validations.\n",
    "assert project_id, \"⚠️ Please provide a Google Cloud project ID\"\n",
    "\n",
    "# Configure gcloud.\n",
    "!gcloud config set project {project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-oqMC5Ox-ZM"
   },
   "source": [
    "## Enable APIs for AlloyDB and Vertex AI within your project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-bzfFb4A-xK"
   },
   "source": [
    "You will need to enable these APIs in order to create an AlloyDB database and utilize Vertex AI as an embeddings service!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKWrwyfzyTwH"
   },
   "outputs": [],
   "source": [
    "# enable GCP services\n",
    "!gcloud services enable alloydb.googleapis.com aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gn8g7-wCyZU6"
   },
   "source": [
    "## Set up AlloyDB\n",
    "You will need a Postgres AlloyDB instance for the following stages of this notebook. Please set the following variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8q2lc-Po1mPv"
   },
   "outputs": [],
   "source": [
    "# @markdown Please fill in the both the Google Cloud region and name of your AlloyDB instance. Once filled in, run the cell.\n",
    "\n",
    "# Please fill in these values.\n",
    "region = \"us-central1\"  # @param {type:\"string\"}\n",
    "cluster_name = \"my-cluster\"  # @param {type:\"string\"}\n",
    "instance_name = \"my-primary\"  # @param {type:\"string\"}\n",
    "database_name = \"langchain\"  # @param {type:\"string\"}\n",
    "password = input(\"Please provide a password to be used for 'postgres' database user: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T616pEOUygYQ"
   },
   "source": [
    "### Create an AlloyDB Instance\n",
    "If you have already created an AlloyDB Cluster and Instance, you can skip these steps and skip to the connectivity section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyZYX4Jo1vfh"
   },
   "source": [
    "> ⏳ - Creating an AlloyDB cluster may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XXI1uUu3y8gc"
   },
   "outputs": [],
   "source": [
    "# Quick input validations.\n",
    "assert region, \"⚠️ Please provide a Google Cloud region\"\n",
    "assert instance_name, \"⚠️ Please provide the name of your instance\"\n",
    "assert database_name, \"⚠️ Please provide the name of your database_name\"\n",
    "\n",
    "# create the AlloyDB Cluster\n",
    "!gcloud beta alloydb clusters create {cluster_name} --password={password} --region={region}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8LkscYH5Vfp"
   },
   "source": [
    "Create an instance attached to our cluster with the following command.\n",
    "> ⏳ - Creating an AlloyDB instance may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TkqQSWoY5Kab"
   },
   "outputs": [],
   "source": [
    "!gcloud beta alloydb instances create {instance_name} --instance-type=PRIMARY --cpu-count=2 --region={region} --cluster={cluster_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXsQ1UJv4ZVJ"
   },
   "source": [
    "To connect to your AlloyDB instance from this notebook, you will need to enable public IP on your instance. Alternatively, you can follow [these instructions](https://cloud.google.com/alloydb/docs/connect-external) to connect to an AlloyDB for PostgreSQL instance with Private IP from outside your VPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPVWsQB04Yyl"
   },
   "outputs": [],
   "source": [
    "!gcloud beta alloydb instances update {instance_name} --region={region} --cluster={cluster_name} --assign-inbound-public-ip=ASSIGN_IPV4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjA6AiAzB2Du"
   },
   "source": [
    "Now create a connection pool to connect to our instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zsLi0a7FIYjT"
   },
   "outputs": [],
   "source": [
    "from google.cloud.alloydb.connector import Connector, IPTypes\n",
    "import sqlalchemy\n",
    "\n",
    "\n",
    "connection_string = f\"projects/{project_id}/locations/{region}/clusters/{cluster_name}/instances/{instance_name}\"\n",
    "# initialize Connector object\n",
    "connector = Connector()\n",
    "\n",
    "\n",
    "# function to return the database connection\n",
    "def getconn():\n",
    "    conn = connector.connect(\n",
    "        connection_string,\n",
    "        \"pg8000\",\n",
    "        user=\"postgres\",\n",
    "        password=password,\n",
    "        db=\"postgres\",\n",
    "        enable_iam_auth=False,\n",
    "        ip_type=IPTypes.PUBLIC,\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "\n",
    "# create connection pool\n",
    "pool = sqlalchemy.create_engine(\n",
    "    \"postgresql+pg8000://\", creator=getconn, isolation_level=\"AUTOCOMMIT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_yNN1MnJpTR"
   },
   "source": [
    "### Create a Database\n",
    "\n",
    "Next you will create database to store the data for this application using the connection pool. Enabling public IP takes a few minutes, you may get an error that there is no public IP address. Please wait and retry this step if you hit an error!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hPE6tt5eJqhq"
   },
   "outputs": [],
   "source": [
    "with pool.connect() as db_conn:\n",
    "    db_conn.execute(sqlalchemy.text(f\"CREATE DATABASE {database_name}\"))\n",
    "connector.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_yNN1MnJpTR"
   },
   "source": [
    "#### Connect to our New Database\n",
    "\n",
    "Now you will add in a connection function that connects to your new database!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zsLi0a7FIYjT"
   },
   "outputs": [],
   "source": [
    "from google.cloud.alloydb.connector import Connector, IPTypes\n",
    "import sqlalchemy\n",
    "\n",
    "\n",
    "connection_string = f\"projects/{project_id}/locations/{region}/clusters/{cluster_name}/instances/{instance_name}\"\n",
    "# initialize Connector object\n",
    "connector = Connector()\n",
    "\n",
    "\n",
    "# function to return the database connection\n",
    "def getconn():\n",
    "    conn = connector.connect(\n",
    "        connection_string,\n",
    "        \"pg8000\",\n",
    "        user=\"postgres\",\n",
    "        password=password,\n",
    "        db=database_name,\n",
    "        enable_iam_auth=False,\n",
    "        ip_type=IPTypes.PUBLIC,\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "\n",
    "# create connection pool\n",
    "pool = sqlalchemy.create_engine(\"postgresql+pg8000://\", creator=getconn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdolCWyatZmG"
   },
   "source": [
    "### Import data to your database\n",
    "\n",
    "Now that you have your database, you will need to import data! We will be using a [Netflix Dataset from Kaggle](https://www.kaggle.com/datasets/shivamb/netflix-shows). Here is what the data looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36-FBKzJ-tLa"
   },
   "source": [
    "| show_id | type    | title                | director         | cast                                                                                                                                                  | country       | date_added        | release_year | rating | duration  | listed_in                                    | description                                                                                                                                                                           |\n",
    "|---------|---------|----------------------|------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|-------------------|--------------|--------|-----------|----------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| s1      | Movie   | Dick Johnson Is Dead | Kirsten Johnson  |                                                                                                                                                        | United States | September 25, 2021 | 2020         | PG-13  | 90 min    | Documentaries                                | As her father nears the end of his life, filmmaker Kirsten Johnson stages his death in inventive and comical ways to help them both face the inevitable.                              |\n",
    "| s2      | TV Show | Blood & Water        |                  | Ama Qamata, Khosi Ngema, Gail Mabalane, Thabang Molaba, Dillon Windvogel, Natasha Thahane, Arno Greeff, Xolile Tshabalala, Getmore Sithole, Cindy Mahlangu, Ryle De Morny, Greteli Fincham, Sello Maake Ka-Ncube, Odwa Gwanya, Mekaila Mathys, Sandi Schultz, Duane Williams, Shamilla Miller, Patrick Mofokeng | South Africa  | September 24, 2021 | 2021         | TV-MA  | 2 Seasons | International TV Shows, TV Dramas, TV Mysteries | After crossing paths at a party, a Cape Town teen sets out to prove whether a private-school swimming star is her sister who was abducted at birth.                                   |\n",
    "| s3      | TV Show | Ganglands            | Julien Leclercq  | Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabiha Akkari, Sofia Lesaffre, Salim Kechiouche, Noureddine Farihi, Geert Van Rampelberg, Bakary Diombera                                   |               | September 24, 2021 | 2021         | TV-MA  | 1 Season  | Crime TV Shows, International TV Shows, TV Action & Adventure | To protect his family from a powerful drug lord, skilled thief Mehdi and his expert team of robbers are pulled into a violent and deadly turf war.                                     |\n",
    "| s4      | TV Show | Jailbirds New Orleans |                  |                                                                                                                                                        |               | September 24, 2021 | 2021         | TV-MA  | 1 Season  | Docuseries, Reality TV                        | Feuds, flirtations and toilet talk go down among the incarcerated women at the Orleans Justice Center in New Orleans on this gritty reality series.                                   |\n",
    "| s5      | TV Show | Kota Factory         |                  | Mayur More, Jitendra Kumar, Ranjan Raj, Alam Khan, Ahsaas Channa, Revathi Pillai, Urvi Singh, Arun Kumar                                                 | India        | September 24, 2021 | 2021         | TV-MA  | 2 Seasons | International TV Shows, Romantic TV Shows, TV Comedies | In a city of coaching centers known to train India’s finest collegiate minds, an earnest but unexceptional student and his friends navigate campus life. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQ2KWsYI_Msa"
   },
   "source": [
    "The following code has been prepared code to help insert the CSV data into your AlloyDB for PostgreSQL database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dzr-2VZIkvtY"
   },
   "source": [
    "Download the CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KkIQ2zSvQkN"
   },
   "outputs": [],
   "source": [
    "!gsutil cp gs://cloud-samples-data/langchain/common/first_five_netflix_titles.csv ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFU13dCBlYHh"
   },
   "source": [
    "The download can be verified by the following command or using the \"Files\" tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQBs10I8vShh"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2H7rorG9Ivur"
   },
   "source": [
    "In this next step you will:\n",
    "\n",
    "1. Create the table into store data\n",
    "2. And insert the data from the CSV into the database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qCsM2KXbdYiv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "create_table_cmd = sqlalchemy.text(\n",
    "    'CREATE TABLE netflix_titles ( \\\n",
    "    show_id VARCHAR, \\\n",
    "    type VARCHAR, \\\n",
    "    title VARCHAR, \\\n",
    "    director VARCHAR, \\\n",
    "    \"cast\" VARCHAR, \\\n",
    "    country VARCHAR, \\\n",
    "    date_added VARCHAR, \\\n",
    "    release_year INTEGER, \\\n",
    "    rating VARCHAR, \\\n",
    "    duration VARCHAR, \\\n",
    "    listed_in VARCHAR, \\\n",
    "    description TEXT \\\n",
    "    )',\n",
    ")\n",
    "\n",
    "netflix_data = \"/content/first_five_netflix_titles.csv\"\n",
    "\n",
    "df = pd.read_csv(netflix_data)\n",
    "insert_data_cmd = sqlalchemy.text(\n",
    "    \"\"\"\n",
    "    INSERT INTO netflix_titles VALUES (:show_id, :type, :title, :director,\n",
    "      :cast, :country, :date_added, :release_year, :rating,\n",
    "      :duration, :listed_in, :description)\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "parameter_map = [\n",
    "    {\n",
    "        \"show_id\": row[\"show_id\"],\n",
    "        \"type\": row[\"type\"],\n",
    "        \"title\": row[\"title\"],\n",
    "        \"director\": row[\"director\"],\n",
    "        \"cast\": row[\"cast\"],\n",
    "        \"country\": row[\"country\"],\n",
    "        \"date_added\": row[\"date_added\"],\n",
    "        \"release_year\": row[\"release_year\"],\n",
    "        \"rating\": row[\"rating\"],\n",
    "        \"duration\": row[\"duration\"],\n",
    "        \"listed_in\": row[\"listed_in\"],\n",
    "        \"description\": row[\"description\"],\n",
    "    }\n",
    "    for index, row in df.iterrows()\n",
    "]\n",
    "\n",
    "with pool.connect() as db_conn:\n",
    "    db_conn.execute(create_table_cmd)\n",
    "    db_conn.execute(\n",
    "        insert_data_cmd,\n",
    "        parameter_map,\n",
    "    )\n",
    "    db_conn.commit()\n",
    "connector.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsGS80H04bDN"
   },
   "source": [
    "## Use case 1: AlloyDB for Postgres as a document loader\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Now that you have data in your database, you are ready to use AlloyDB for PostgreSQL as a document loader. This means you will pull data from the database and load it into memory as documents. These documents can be used to create a vector store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CQgPON8dwSK"
   },
   "source": [
    "First, create a connection to your AlloyDB for PostgreSQL instance using the `AlloyDBEngine` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zrwTsWHMkQ_v"
   },
   "outputs": [],
   "source": [
    "from langchain_google_alloydb_pg import AlloyDBEngine, Column, AlloyDBLoader\n",
    "\n",
    "engine = AlloyDBEngine.from_instance(\n",
    "    project_id=project_id,\n",
    "    instance=instance_name,\n",
    "    region=region,\n",
    "    cluster=cluster_name,\n",
    "    database=database_name,\n",
    "    user=\"postgres\",\n",
    "    password=password,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8s-C0P-Oee69"
   },
   "source": [
    "The `AlloyDBLoader` requires an `AlloyDBEngine` object to define the database connection and a `query` to define which data is to be retrieved. The `content_columns` argument can be used to define the columns that will be used as \"content\" in the document object we will later construct. The rest of the columns in that table will become the \"metadata\" associated with the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2SdFJT6Vece1"
   },
   "outputs": [],
   "source": [
    "table_name = \"netflix_titles\"\n",
    "content_columns = [\"title\", \"director\", \"cast\", \"description\"]\n",
    "loader = await AlloyDBLoader.create(\n",
    "    engine=engine,\n",
    "    query=f\"SELECT * FROM {table_name};\",\n",
    "    content_columns=content_columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dsL-KFrmfuS1"
   },
   "source": [
    "Use method `aload()` to pull documents from out database. You can see the first 5 documents from the database here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4zTx-HLfwmW"
   },
   "outputs": [],
   "source": [
    "documents = await loader.aload()\n",
    "print(f\"Loaded {len(documents)} from the database. 5 Examples:\")\n",
    "for doc in documents[:5]:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, you just used AlloyDB for Postgres as a document loader!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9uLV3bs4noo"
   },
   "source": [
    "## Use case 2: AlloyDB for PostgreSQL as Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duVsSeMcgEWl"
   },
   "source": [
    "Now, you will learn how to put all of the documents into a vector store so that you perform a vector search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jfH8oQJ945Ko"
   },
   "source": [
    "### Create Your Vector Store table\n",
    "\n",
    "Create a vector store table that can preserve the Document's metadata by using the method `init_vectorstore_table` and defining specific metadata columns. The vector size is required. The example shows the vector size, `768`, that corresponds with the length of the vectors computed by the model our embeddings service uses, Vertex AI's `textembedding-gecko`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_rmjywG47pv"
   },
   "outputs": [],
   "source": [
    "from langchain_google_alloydb_pg import AlloyDBEngine, Column\n",
    "\n",
    "sample_vector_table_name = \"movie_vector_table_samples\"\n",
    "\n",
    "engine = AlloyDBEngine.from_instance(\n",
    "    project_id=project_id,\n",
    "    instance=instance_name,\n",
    "    region=region,\n",
    "    cluster=cluster_name,\n",
    "    database=database_name,\n",
    "    user=\"postgres\",\n",
    "    password=password,\n",
    ")\n",
    "\n",
    "engine.init_vectorstore_table(\n",
    "    sample_vector_table_name,\n",
    "    vector_size=768,\n",
    "    metadata_columns=[\n",
    "        Column(\"show_id\", \"VARCHAR\", nullable=True),\n",
    "        Column(\"type\", \"VARCHAR\", nullable=True),\n",
    "        Column(\"country\", \"VARCHAR\", nullable=True),\n",
    "        Column(\"date_added\", \"VARCHAR\", nullable=True),\n",
    "        Column(\"release_year\", \"INTEGER\", nullable=True),\n",
    "        Column(\"rating\", \"VARCHAR\", nullable=True),\n",
    "        Column(\"duration\", \"VARCHAR\", nullable=True),\n",
    "        Column(\"listed_in\", \"VARCHAR\", nullable=True),\n",
    "    ],\n",
    "    overwrite_existing=True,  # Enabling this will recreate the table if exists.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KG6rwEuJLNIo"
   },
   "source": [
    "### Try inserting the documents into the vector table\n",
    "\n",
    "Next, you will create a `AlloyDBVectorStore` object that connects to the new AlloyDB database table to store the data from the documents. Note that for each row, the embedding service will be called to compute the embeddings to store in the vector table. Pricing details can be found [here](https://cloud.google.com/vertex-ai/pricing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wo4-7EYCIFF9"
   },
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain_google_alloydb_pg import AlloyDBVectorStore, AlloyDBEngine\n",
    "\n",
    "# Initialize the embedding service. In this case we are using version 003 of Vertex AI's textembedding-gecko model. In general, it is good practice to specify the model version used.\n",
    "embeddings_service = VertexAIEmbeddings(\n",
    "    model_name=\"textembedding-gecko@003\", project=project_id\n",
    ")\n",
    "\n",
    "engine = AlloyDBEngine.from_instance(\n",
    "    project_id=project_id,\n",
    "    instance=instance_name,\n",
    "    region=region,\n",
    "    cluster=cluster_name,\n",
    "    database=database_name,\n",
    "    user=\"postgres\",\n",
    "    password=password,\n",
    ")\n",
    "\n",
    "vector_store = AlloyDBVectorStore.create_sync(\n",
    "    engine=engine,\n",
    "    embedding_service=embeddings_service,\n",
    "    table_name=sample_vector_table_name,\n",
    "    metadata_columns=[\n",
    "        \"show_id\",\n",
    "        \"type\",\n",
    "        \"country\",\n",
    "        \"date_added\",\n",
    "        \"release_year\",\n",
    "        \"duration\",\n",
    "        \"listed_in\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fr1rP6KQ-8ag"
   },
   "source": [
    "Now, add the documents data into the vector table. Here is a code example to load the first 5 documents in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CTks8Cy--93B"
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "docs_to_load = documents[:5]\n",
    "\n",
    "# ! Uncomment the following line to load all 8,800+ documents to the database vector table with calling the embedding service.\n",
    "# docs_to_load = documents\n",
    "\n",
    "ids = [str(uuid.uuid4()) for i in range(len(docs_to_load))]\n",
    "vector_store.add_documents(docs_to_load, ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29iztdvfL2BN"
   },
   "source": [
    "### Import the rest of your data into your vector table\n",
    "\n",
    "You don't have to call the embedding service 8,800 times to load all the documents for the demo. Instead, we have prepared a CSV with the all 8,800+ rows with pre-computed embeddings in a CSV file. You can import the CSV using `gsutil`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dE4oQiNyWdC"
   },
   "outputs": [],
   "source": [
    "!gsutil cp gs://cloud-samples-data/langchain/alloydb/netflix_titles_embeddings.csv ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1TXnKU_DznX"
   },
   "source": [
    "Use the following code to insert the pregenerated embeddings into your vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDIRYfUyyVyI"
   },
   "outputs": [],
   "source": [
    "netflix_data = \"/content/langchain_alloydb_netflix_computed_embeddings.csv\"\n",
    "df = pd.read_csv(netflix_data)\n",
    "insert_data_cmd = sqlalchemy.text(\n",
    "    \"\"\"\n",
    "    INSERT INTO movie_vector_table_samples VALUES (:langchain_id, :content, :embedding, :show_id,\n",
    "      :type, :country, :date_added, :release_year, :rating,\n",
    "      :duration, :listed_in, :langchain_metadata)\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "parameter_map = [\n",
    "    {\n",
    "        \"langchain_id\": row[\"langchain_id\"],\n",
    "        \"content\": row[\"content\"],\n",
    "        \"embedding\": row[\"embedding\"],\n",
    "        \"show_id\": row[\"show_id\"],\n",
    "        \"type\": row[\"type\"],\n",
    "        \"country\": row[\"country\"],\n",
    "        \"date_added\": row[\"date_added\"],\n",
    "        \"release_year\": row[\"release_year\"],\n",
    "        \"rating\": row[\"rating\"],\n",
    "        \"duration\": row[\"duration\"],\n",
    "        \"listed_in\": row[\"listed_in\"],\n",
    "        \"langchain_metadata\": row[\"langchain_metadata\"],\n",
    "    }\n",
    "    for index, row in df.iterrows()\n",
    "]\n",
    "\n",
    "with pool.connect() as db_conn:\n",
    "    db_conn.execute(\n",
    "        insert_data_cmd,\n",
    "        parameter_map,\n",
    "    )\n",
    "    db_conn.commit()\n",
    "connector.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZM_OFzZrQEPs"
   },
   "source": [
    "# Use case 3: AlloyDB for PostgreSQL as Chat Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxqIPQtjDquk"
   },
   "source": [
    "Next you will add chat history (called “memory” in the context of LangChain) to our application so the LLM can retain context and information across multiple interactions, leading to more coherent and sophisticated conversations or text generation. You can use AlloyDB for PostgreSQL as “memory” storage in our application so that the LLM can use context from prior conversations to better answer the user’s prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vyYQILyoEAqg"
   },
   "outputs": [],
   "source": [
    "from langchain_google_alloydb_pg import AlloyDBChatMessageHistory, AlloyDBEngine\n",
    "\n",
    "engine = AlloyDBEngine.from_instance(\n",
    "    project_id=project_id,\n",
    "    instance=instance_name,\n",
    "    region=region,\n",
    "    cluster=cluster_name,\n",
    "    database=database_name,\n",
    "    user=\"postgres\",\n",
    "    password=password,\n",
    ")\n",
    "message_table_name = \"message_store\"\n",
    "\n",
    "engine.init_chat_history_table(table_name=message_table_name)\n",
    "\n",
    "chat_history = AlloyDBChatMessageHistory.create_sync(\n",
    "    engine,\n",
    "    session_id=\"my-test-session\",\n",
    "    table_name=message_table_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yuXYLTCl2K1"
   },
   "source": [
    "Here is an example of how you would add a user message and how you would add an AI message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qDVoTWZal0ZF"
   },
   "outputs": [],
   "source": [
    "chat_history.add_user_message(\"Hi!\")\n",
    "chat_history.add_ai_message(\"Hello there. I'm a model and am happy to help!\")\n",
    "\n",
    "chat_history.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0O9mta8RQ0v"
   },
   "source": [
    "## Conversational RAG Chain backed by AlloyDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2OxF3JoNA7J"
   },
   "source": [
    "Try using all 3 integrations with the `ConversationalRetrievalChain`.\n",
    "\n",
    "You will build a chatbot that can answer movie related questions based on the vector search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ukjOO-sNQ8_"
   },
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAIEmbeddings, VertexAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_alloydb_pg import (\n",
    "    AlloyDBEngine,\n",
    "    AlloyDBVectorStore,\n",
    "    AlloyDBChatMessageHistory,\n",
    ")\n",
    "\n",
    "# Intialize the embedding service\n",
    "embeddings_service = VertexAIEmbeddings(\n",
    "    model_name=\"textembedding-gecko@003\", project=project_id\n",
    ")\n",
    "\n",
    "# Intialize the engine\n",
    "engine = AlloyDBEngine.from_instance(\n",
    "    project_id=project_id,\n",
    "    instance=instance_name,\n",
    "    region=region,\n",
    "    cluster=cluster_name,\n",
    "    database=database_name,\n",
    "    user=\"postgres\",\n",
    "    password=password,\n",
    ")\n",
    "# Intialize the Vector Store\n",
    "vector_store = AlloyDBVectorStore.create_sync(\n",
    "    engine=engine,\n",
    "    embedding_service=embeddings_service,\n",
    "    table_name=sample_vector_table_name,\n",
    "    metadata_columns=[\n",
    "        \"show_id\",\n",
    "        \"type\",\n",
    "        \"country\",\n",
    "        \"date_added\",\n",
    "        \"release_year\",\n",
    "        \"duration\",\n",
    "        \"listed_in\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Intialize the AlloyDBChatMessageHistory\n",
    "chat_history = AlloyDBChatMessageHistory.create_sync(\n",
    "    engine,\n",
    "    session_id=\"my-test-session\",\n",
    "    table_name=\"message_store\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ytlz9D3LmcU7"
   },
   "source": [
    "Create a prompt for the LLM. Here we can add instructions specific to our application, such as \"Don't make things up\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LoAHNdrWmW9W"
   },
   "outputs": [],
   "source": [
    "# Prepare some prompt templates for the ConversationalRetrievalChain\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"Use all the information from the context and the conversation history to answer new question. If you see the answer in previous conversation history or the context. \\\n",
    "Answer it with clarifying the source information. If you don't see it in the context or the chat history, just say you \\\n",
    "didn't find the answer in the given data. Don't make things up.\n",
    "\n",
    "Previous conversation history from the questioner. \"Human\" was the user who's asking the new question. \"Assistant\" was you as the assistant:\n",
    "```{chat_history}\n",
    "```\n",
    "\n",
    "Vector search result of the new question:\n",
    "```{context}\n",
    "```\n",
    "\n",
    "New Question:\n",
    "```{question}```\n",
    "\n",
    "Answer:\"\"\",\n",
    "    input_variables=[\"context\", \"question\", \"chat_history\"],\n",
    ")\n",
    "condense_question_prompt_passthrough = PromptTemplate(\n",
    "    template=\"\"\"Repeat the following question:\n",
    "{question}\n",
    "\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsGe-bW5m0H1"
   },
   "source": [
    "Next, create a retriever from the vector store in order to retrieve similar documents via a vector search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1nI0xkJamvXt"
   },
   "outputs": [],
   "source": [
    "# Initialize retriever, llm and memory for the chain\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 5, \"lambda_mult\": 0.8}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3maZ8SLlneYJ"
   },
   "source": [
    "Next, initialize our LLM, in this case we are using Vertex AI's \"gemini-pro\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VBWhg-ihnnxF"
   },
   "outputs": [],
   "source": [
    "llm = VertexAI(model_name=\"gemini-pro\", project=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hN8mpXdtnocg"
   },
   "source": [
    "Clear your chat history, so that our application starts without any prior context to other conversations we have had with the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UkPcEpJno5Y"
   },
   "outputs": [],
   "source": [
    "chat_history.clear()\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    chat_memory=chat_history,\n",
    "    output_key=\"answer\",\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDAT2koSn8Mz"
   },
   "source": [
    "Now, create a conversational retrieval chain. This will allow the LLM to use chat history in it's responses, meaning we can ask it follow up questions to our questions instead of having to start from scratch after each inquiry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Fu8fKdEn8h8"
   },
   "outputs": [],
   "source": [
    "# create the ConversationalRetrievalChain\n",
    "rag_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    verbose=False,\n",
    "    memory=memory,\n",
    "    condense_question_prompt=condense_question_prompt_passthrough,\n",
    "    combine_docs_chain_kwargs={\"prompt\": prompt},\n",
    ")\n",
    "\n",
    "# ask some questions\n",
    "q = \"What movie was Brad Pitt in?\"\n",
    "ans = rag_chain({\"question\": q, \"chat_history\": chat_history})[\"answer\"]\n",
    "print(f\"Question: {q}\\nAnswer: {ans}\\n\")\n",
    "\n",
    "q = \"How about Jonny Depp?\"\n",
    "ans = rag_chain({\"question\": q, \"chat_history\": chat_history})[\"answer\"]\n",
    "print(f\"Question: {q}\\nAnswer: {ans}\\n\")\n",
    "\n",
    "q = \"Are there movies about animals?\"\n",
    "ans = rag_chain({\"question\": q, \"chat_history\": chat_history})[\"answer\"]\n",
    "print(f\"Question: {q}\\nAnswer: {ans}\\n\")\n",
    "\n",
    "# browser the chat history\n",
    "chat_history.messages"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
