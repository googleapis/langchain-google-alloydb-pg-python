{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "w2ahCzV6-B-C",
      "metadata": {
        "id": "w2ahCzV6-B-C"
      },
      "source": [
        "# Migrate PineconeVectorStore to Langchain AlloyDBVectorStore"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aZuO18vf-IFp",
      "metadata": {
        "id": "aZuO18vf-IFp"
      },
      "source": [
        "Given a pinecone index, the following code fetches the data from pinecone\n",
        "in batches and uploads to an AlloyDBVectorStore."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FDCqcfl9-JUd",
      "metadata": {
        "id": "FDCqcfl9-JUd"
      },
      "source": [
        "## License"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75tWucdJ9a8M",
      "metadata": {
        "id": "75tWucdJ9a8M"
      },
      "source": [
        "Copyright 2025 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-cvw1Y5b-M1Q",
      "metadata": {
        "id": "-cvw1Y5b-M1Q"
      },
      "source": [
        "## Install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xA3EV8fo9Zjp",
      "metadata": {
        "id": "xA3EV8fo9Zjp"
      },
      "outputs": [],
      "source": [
        "!pip install -q google-cloud-aiplatform[reasoningengine,langchain]==1.82.0 \\\n",
        "google-cloud-resource-manager==1.14.1 \\\n",
        "langchain-community==0.3.18 \\\n",
        "langchain-google-alloydb-pg==0.9.3 \\\n",
        "langchain-google-vertexai==2.0.14 \\\n",
        "pinecone==6.0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6GPZS8Cj-ukK",
      "metadata": {
        "id": "6GPZS8Cj-ukK"
      },
      "source": [
        "## Define Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ANDyPlXJ9Zgz",
      "metadata": {
        "id": "ANDyPlXJ9Zgz"
      },
      "outputs": [],
      "source": [
        "# TODO(dev): Replace the values below\n",
        "PINECONE_API_KEY = \"my-pc-api-key\" # @param {type:\"string\"}\n",
        "PINECONE_INDEX_NAME = \"my-pc-index-name\" # @param {type:\"string\"}\n",
        "PROJECT_ID = \"my-project-id\" # @param {type:\"string\"}\n",
        "REGION = \"us-central1\" # @param {type:\"string\"}\n",
        "CLUSTER = \"my-cluster\" # @param {type:\"string\"}\n",
        "INSTANCE = \"my-instance\" # @param {type:\"string\"}\n",
        "DB_NAME = \"my-db\" # @param {type:\"string\"}\n",
        "DB_USER = \"postgres\" # @param {type:\"string\"}\n",
        "DB_PWD = \"secret-password\" # @param {type:\"string\"}\n",
        "\n",
        "# TODO(developer): Optional, change the values below.\n",
        "PINECONE_NAMESPACE = \"\" # @param {type:\"string\"}\n",
        "VECTOR_SIZE = 768 # @param {type:\"number\"}\n",
        "PINECONE_BATCH_SIZE = 10 # @param {type:\"number\"}\n",
        "ALLOYDB_TABLE_NAME = \"alloydb_table\" # @param {type:\"string\"}\n",
        "MAX_CONCURRENCY = 100 # @param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "w2O1xPhN_d8A",
      "metadata": {
        "id": "w2O1xPhN_d8A"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4MIM_aPg9Za2",
      "metadata": {
        "id": "4MIM_aPg9Za2"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import uuid\n",
        "from typing import Any, Iterator, List, Optional, Dict\n",
        "\n",
        "from google.cloud.alloydb.connector import IPTypes\n",
        "from pinecone import Index  # type: ignore"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6Qx-Xzbo_uGz",
      "metadata": {
        "id": "6Qx-Xzbo_uGz"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "x1sZjX3-_vrI",
      "metadata": {
        "id": "x1sZjX3-_vrI"
      },
      "source": [
        "### get_ids_batch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ohPqYX-i9YxB",
      "metadata": {
        "id": "ohPqYX-i9YxB"
      },
      "outputs": [],
      "source": [
        "def get_ids_batch(\n",
        "    pinecone_index: Index,\n",
        "    pinecone_namespace: str = PINECONE_NAMESPACE,\n",
        "    pinecone_batch_size: int = PINECONE_BATCH_SIZE,\n",
        ") -> Iterator[list[str]]:\n",
        "    \"\"\"\n",
        "    Fetches IDs from a Pinecone index in batches, handling pagination correctly.\n",
        "    Uses a generator to yield batches of IDs.\n",
        "    \"\"\"\n",
        "    # [START pinecone_get_ids_batch]\n",
        "    results = pinecone_index.list_paginated(\n",
        "        prefix=\"\", namespace=pinecone_namespace, limit=pinecone_batch_size\n",
        "    )\n",
        "    ids = [v.id for v in results.vectors]\n",
        "    if ids: # Prevents yielding an empty list.\n",
        "      yield ids\n",
        "\n",
        "    # Corrected pagination check:  Check BOTH pagination and pagination.next\n",
        "    while results.pagination is not None and results.pagination.get(\"next\") is not None:\n",
        "        pagination_token = results.pagination.get(\"next\")\n",
        "        results = pinecone_index.list_paginated(\n",
        "            prefix=\"\", pagination_token=pagination_token, namespace=pinecone_namespace, limit=pinecone_batch_size\n",
        "        )\n",
        "\n",
        "        # Extract and yield the next batch of IDs\n",
        "        ids = [v.id for v in results.vectors]\n",
        "        if ids: # Prevents yielding an empty list.\n",
        "            yield ids\n",
        "    # [END pinecone_get_ids_batch]\n",
        "    print(\"Pinecone client fetched all ids from index.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5-dt8LjU_1TW",
      "metadata": {
        "id": "5-dt8LjU_1TW"
      },
      "source": [
        "### get_data_batch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Zg8uaOA2_3KF",
      "metadata": {
        "id": "Zg8uaOA2_3KF"
      },
      "outputs": [],
      "source": [
        "def get_data_batch(\n",
        "    pinecone_index: Index, pinecone_namespace: str, pinecone_batch_size: int\n",
        ") -> Iterator[tuple[List[uuid.UUID], List[str], List[List[float]], List[Dict[str, Any]]]]:\n",
        "    id_iterator = get_ids_batch(pinecone_index, pinecone_namespace, pinecone_batch_size)\n",
        "    \"\"\"\n",
        "    Fetches data (vectors, metadata, etc.) from Pinecone in batches, given an index and namespace.\n",
        "    Uses a generator to yield batches of data.\n",
        "    \"\"\"\n",
        "    # [START pinecone_get_data_batch]\n",
        "    # Iterate through the IDs and download their contents\n",
        "    for ids in id_iterator:\n",
        "        if not ids:\n",
        "            return None\n",
        "        all_data = pinecone_index.fetch(ids=ids, namespace=pinecone_namespace)\n",
        "        ids_batch: List[uuid.UUID] = []  # Explicitly type as List[uuid.UUID]\n",
        "        embeddings = []\n",
        "        contents = []\n",
        "        metadatas = []\n",
        "\n",
        "        # Process each vector in the current batch\n",
        "        for vector_id, vector in all_data.vectors.items():\n",
        "            # You might need to update this data translation logic according to your field names\n",
        "            # id is the unqiue identifier for the content\n",
        "            ids_batch.append(uuid.uuid4()) # Generate UUIDs for AlloyDB\n",
        "            embeddings.append(vector.values)\n",
        "            # Check if 'title' exists in metadata before accessing\n",
        "            if 'title' in vector.metadata:\n",
        "                contents.append(str(vector.metadata['title']))\n",
        "                del vector.metadata['title']  # Remove 'title' after processing\n",
        "            else:\n",
        "                contents.append(\"\")  # Or handle the missing 'title' field appropriately\n",
        "            metadatas.append(vector.metadata)\n",
        "\n",
        "        # Yield the current batch of results\n",
        "        yield ids_batch, contents, embeddings, metadatas\n",
        "    # [END pinecone_get_data_batch]\n",
        "    print(\"Pinecone client fetched all data from index.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LphpFhs8AFg1",
      "metadata": {
        "id": "LphpFhs8AFg1"
      },
      "source": [
        "## Execute Migration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BaN49DnW_3FC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaN49DnW_3FC",
        "outputId": "e07088b8-d344-4b5e-c35e-7312adcb7c0e"
      },
      "outputs": [],
      "source": [
        "async def main(\n",
        "    pinecone_api_key: str = PINECONE_API_KEY,\n",
        "    pinecone_index_name: str = PINECONE_INDEX_NAME,\n",
        "    pinecone_namespace: str = PINECONE_NAMESPACE,\n",
        "    vector_size: int = VECTOR_SIZE,\n",
        "    pinecone_batch_size: int = PINECONE_BATCH_SIZE,\n",
        "    project_id: str = PROJECT_ID,\n",
        "    region: str = REGION,\n",
        "    cluster: str = CLUSTER,\n",
        "    instance: str = INSTANCE,\n",
        "    alloydb_table: str = ALLOYDB_TABLE_NAME,\n",
        "    db_name: str = DB_NAME,\n",
        "    db_user: str = DB_USER,\n",
        "    db_pwd: str = DB_PWD,\n",
        "    max_concurrency: int = MAX_CONCURRENCY,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Main function to orchestrate the migration from Pinecone to AlloyDB.\n",
        "    \"\"\"\n",
        "    # [START pinecone_get_client]\n",
        "    from pinecone import Pinecone  # type: ignore\n",
        "\n",
        "    pinecone_client = Pinecone(api_key=pinecone_api_key)\n",
        "    pinecone_index = pinecone_client.Index(pinecone_index_name)\n",
        "    # [END pinecone_get_client]\n",
        "    print(\"Pinecone index reference initiated.\")\n",
        "\n",
        "    # [START pinecone_vectorstore_alloydb_migration_get_client]\n",
        "    from langchain_google_alloydb_pg import AlloyDBEngine\n",
        "\n",
        "    alloydb_engine = await AlloyDBEngine.afrom_instance(\n",
        "        project_id=project_id,\n",
        "        region=region,\n",
        "        cluster=cluster,\n",
        "        instance=instance,\n",
        "        database=db_name,\n",
        "        user=db_user,\n",
        "        password=db_pwd,\n",
        "        ip_type=IPTypes.PRIVATE,\n",
        "    )\n",
        "    # [END pinecone_vectorstore_alloydb_migration_get_client]\n",
        "    print(\"Langchain AlloyDB client initiated.\")\n",
        "\n",
        "    # [START pinecone_vectorstore_alloydb_migration_create_table]\n",
        "    await alloydb_engine.ainit_vectorstore_table(\n",
        "        table_name=alloydb_table,\n",
        "        vector_size=vector_size,\n",
        "        overwrite_existing=True,\n",
        "        # Customize the ID column types with `id_column` if not using the UUID data type\n",
        "    )\n",
        "    # [END pinecone_vectorstore_alloydb_migration_create_table]\n",
        "    print(\"Langchain AlloyDB vectorstore table created.\")\n",
        "\n",
        "    # [START pinecone_vectorstore_alloydb_migration_embedding_service]\n",
        "    # The VectorStore interface requires an embedding service. This workflow does not\n",
        "    # generate new embeddings, therefore FakeEmbeddings class is used to avoid any costs.\n",
        "    from langchain_core.embeddings import FakeEmbeddings\n",
        "\n",
        "    embeddings_service = FakeEmbeddings(size=vector_size)\n",
        "    # [END pinecone_vectorstore_alloydb_migration_embedding_service]\n",
        "    print(\"Langchain Fake Embeddings service initiated.\")\n",
        "\n",
        "    # [START pinecone_vectorstore_alloydb_migration_vector_store]\n",
        "    from langchain_google_alloydb_pg import AlloyDBVectorStore\n",
        "\n",
        "    vs = await AlloyDBVectorStore.create(\n",
        "        engine=alloydb_engine,\n",
        "        embedding_service=embeddings_service,\n",
        "        table_name=alloydb_table,\n",
        "    )\n",
        "    # [END pinecone_vectorstore_alloydb_migration_vector_store]\n",
        "    print(\"Langchain AlloyDBVectorStore initialized.\")\n",
        "\n",
        "    data_iterator = get_data_batch(\n",
        "        pinecone_index, pinecone_namespace, pinecone_batch_size\n",
        "    )\n",
        "\n",
        "    # [START pinecone_vectorstore_alloydb_migration_insert_data_batch]\n",
        "    pending: set[Any] = set()\n",
        "    for ids, contents, embeddings, metadatas in data_iterator:\n",
        "        pending.add(\n",
        "            asyncio.ensure_future(\n",
        "                vs.aadd_embeddings(\n",
        "                    texts=contents,\n",
        "                    embeddings=embeddings,\n",
        "                    metadatas=metadatas,\n",
        "                    ids=ids,\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "        if len(pending) >= max_concurrency:\n",
        "            _, pending = await asyncio.wait(\n",
        "                pending, return_when=asyncio.FIRST_COMPLETED\n",
        "            )\n",
        "    if pending:\n",
        "        await asyncio.wait(pending)\n",
        "\n",
        "    # [END pinecone_vectorstore_alloydb_migration_insert_data_batch]\n",
        "    print(\"Migration completed, inserted all the batches of data to AlloyDB.\")\n",
        "\n",
        "\n",
        "await main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "admin (Mar 6, 2025, 8:53:14â€¯AM)",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
